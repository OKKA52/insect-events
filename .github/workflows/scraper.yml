name: Daily Scraper

on:
  schedule:
    - cron: '0 21 * * *' # æ¯æ—¥06:00 JSTï¼ˆUTC 21:00ï¼‰
  workflow_dispatch: # æ‰‹å‹•å®Ÿè¡Œã‚‚è¨±å¯

jobs:
  run-scrapers:
    runs-on: ubuntu-latest

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v3

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ”§ Install Playwright browsers # âœ… ã“ã‚Œã‚’è¿½åŠ 
        run: playwright install

      - name: ğŸš€ Run scrape_itakon.py
        run: python scripts/scrapers/scrape_itakon.py

      - name: ğŸš€ Run scrape_ryuyo.py
        run: python scripts/scrapers/scrape_ryuyo.py

      - name: ğŸš€ Run scrape_kamei.py
        run: python scripts/scrapers/scrape_kamei.py

      - name: ğŸš€ Run scrape_ht-shizenkan.py
        run: python scripts/scrapers/scrape_ht-shizenkan.py

      - name: ğŸš€ Run scrape_saitama-sizen.py
        run: python scripts/scrapers/scrape_saitama-sizen.py

      - name: ğŸš€ Run scrape_ibaraki-sizen.py
        run: python scripts/scrapers/scrape_ibaraki-sizen.py
# ğŸ’¡ å¿…è¦ã«å¿œã˜ã¦ä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚é †æ¬¡å®Ÿè¡Œ
